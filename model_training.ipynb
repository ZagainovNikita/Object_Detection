{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import wget\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from object_detection.utils import (\n",
    "    label_map_util, \n",
    "    config_util, \n",
    "    visualization_utils as viz_utils,\n",
    ")\n",
    "from object_detection.builders import model_builder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "TF_RECORD_SCRIPT_PATH = 'tf_record_generator\\generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "MODELS_PATH = './models/'\n",
    "PROTOC_PATH = './protoc/'\n",
    "MOBILE_NET_PATH = './mobile_net/'\n",
    "IMAGES_PATH = './data/images/'\n",
    "LABELMAP_PATH = './data/labelmap.pbtxt'\n",
    "TRAINED_MODEL_PATH = './mobile_net/trained_model/checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODELS_PATH):\n",
    "    !git clone https://github.com/tensorflow/models.git {MODELS_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "\n",
    "if not os.path.exists(PROTOC_PATH):\n",
    "    wget.download(url)\n",
    "    os.makedirs(PROTOC_PATH)\n",
    "    !move protoc-3.15.6-win64.zip {PROTOC_PATH}\n",
    "    !cd {PROTOC_PATH} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(PROTOC_PATH, 'bin'))   \n",
    "    !cd models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.9.18: d:\\Edu\\Python_Projects\\Object_Detection\\.conda\\python.exe\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2023-12-28 16:03:42.349537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-28 16:03:43.238677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1667 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "d:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\object_detection-0.1-py3.9.egg\\object_detection\\builders\\model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W1228 16:03:43.823992 16452 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.2s\n",
      "I1228 16:03:44.542140 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.2s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.21s\n",
      "I1228 16:03:45.752252 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.21s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.48s\n",
      "I1228 16:03:46.231308 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.48s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.53s\n",
      "I1228 16:03:46.760409 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.53s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.32s\n",
      "I1228 16:03:51.090662 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.32s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I1228 16:03:51.110655 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.08s\n",
      "I1228 16:03:51.191566 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.05s\n",
      "I1228 16:03:51.241417 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.05s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.06s\n",
      "I1228 16:03:51.301522 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.31s\n",
      "I1228 16:03:51.611949 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.31s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.31s\n",
      "I1228 16:03:51.922559 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.31s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.3s\n",
      "I1228 16:03:52.224170 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.3s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.31s\n",
      "I1228 16:03:52.534212 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.31s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.33s\n",
      "I1228 16:03:52.859580 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.33s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.1s\n",
      "I1228 16:03:52.959264 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.1s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I1228 16:03:53.549767 16452 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1228 16:03:53.549767 16452 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
      "I1228 16:03:53.549767 16452 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
      "I1228 16:03:53.556785 16452 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1228 16:03:53.655910 16452 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1228 16:03:53.655910 16452 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1228 16:03:53.894892 16452 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1228 16:03:53.894892 16452 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1228 16:03:54.583240 16452 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1228 16:03:54.583240 16452 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1228 16:03:55.200324 16452 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1228 16:03:55.200324 16452 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1228 16:03:56.116639 16452 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1228 16:03:56.116639 16452 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1228 16:03:57.016054 16452 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1228 16:03:57.016054 16452 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1228 16:03:58.160965 16452 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1228 16:03:58.160965 16452 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I1228 16:03:58.444786 16452 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I1228 16:03:58.570402 16452 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1228 16:03:58.950022 16452 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I1228 16:03:58.950022 16452 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
      "I1228 16:03:58.950022 16452 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
      "I1228 16:03:58.957666 16452 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1228 16:03:59.008233 16452 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1228 16:03:59.008233 16452 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1228 16:03:59.465960 16452 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1228 16:03:59.466530 16452 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1228 16:04:00.292093 16452 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1228 16:04:00.292093 16452 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1228 16:04:01.113373 16452 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1228 16:04:01.113373 16452 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1228 16:04:02.233787 16452 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1228 16:04:02.233787 16452 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1228 16:04:03.230473 16452 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1228 16:04:03.230473 16452 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1228 16:04:04.581039 16452 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1228 16:04:04.581039 16452 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I1228 16:04:05.124521 16452 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I1228 16:04:05.227657 16452 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1228 16:04:05.440885 16452 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I1228 16:04:05.440885 16452 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
      "I1228 16:04:05.440885 16452 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
      "I1228 16:04:05.440885 16452 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1228 16:04:05.504134 16452 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1228 16:04:05.504134 16452 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1228 16:04:05.906572 16452 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1228 16:04:05.913127 16452 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1228 16:04:06.688313 16452 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1228 16:04:06.688313 16452 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1228 16:04:07.527384 16452 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1228 16:04:07.527384 16452 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I1228 16:04:08.740558 16452 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I1228 16:04:08.740558 16452 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I1228 16:04:09.871006 16452 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I1228 16:04:09.871006 16452 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I1228 16:04:11.282665 16452 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I1228 16:04:11.282665 16452 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I1228 16:04:11.902114 16452 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I1228 16:04:12.019540 16452 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1228 16:04:12.224043 16452 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I1228 16:04:12.224043 16452 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
      "I1228 16:04:12.224043 16452 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
      "I1228 16:04:12.234678 16452 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I1228 16:04:12.297862 16452 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I1228 16:04:12.297862 16452 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1228 16:04:12.820418 16452 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1228 16:04:12.820418 16452 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1228 16:04:13.734979 16452 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1228 16:04:13.734979 16452 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1228 16:04:14.935386 16452 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1228 16:04:14.935386 16452 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I1228 16:04:16.482429 16452 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I1228 16:04:16.482429 16452 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I1228 16:04:17.948978 16452 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I1228 16:04:17.948978 16452 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I1228 16:04:19.683811 16452 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I1228 16:04:19.683811 16452 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I1228 16:04:20.316995 16452 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I1228 16:04:20.438921 16452 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1228 16:04:20.665750 16452 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I1228 16:04:20.665750 16452 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
      "I1228 16:04:20.665750 16452 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
      "I1228 16:04:20.673974 16452 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1228 16:04:20.730447 16452 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1228 16:04:20.730447 16452 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1228 16:04:21.193897 16452 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1228 16:04:21.193897 16452 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1228 16:04:22.258844 16452 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1228 16:04:22.258844 16452 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I1228 16:04:23.320184 16452 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I1228 16:04:23.320184 16452 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I1228 16:04:25.061043 16452 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I1228 16:04:25.065899 16452 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I1228 16:04:26.874433 16452 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I1228 16:04:26.877997 16452 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I1228 16:04:29.124942 16452 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I1228 16:04:29.124942 16452 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I1228 16:04:29.732021 16452 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I1228 16:04:29.856634 16452 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1228 16:04:30.134558 16452 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I1228 16:04:30.134558 16452 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
      "I1228 16:04:30.134558 16452 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
      "I1228 16:04:30.142872 16452 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1228 16:04:30.199709 16452 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1228 16:04:30.199709 16452 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1228 16:04:30.882291 16452 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1228 16:04:30.882291 16452 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1228 16:04:32.551264 16452 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1228 16:04:32.551264 16452 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I1228 16:04:33.962766 16452 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I1228 16:04:33.962766 16452 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I1228 16:04:36.013331 16452 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I1228 16:04:36.013331 16452 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I1228 16:04:38.048674 16452 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I1228 16:04:38.048674 16452 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I1228 16:04:40.557911 16452 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I1228 16:04:40.557911 16452 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I1228 16:04:41.433443 16452 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I1228 16:04:41.557763 16452 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1228 16:04:41.866293 16452 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I1228 16:04:41.866293 16452 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
      "I1228 16:04:41.866293 16452 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
      "I1228 16:04:41.872344 16452 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I1228 16:04:41.933091 16452 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I1228 16:04:41.933091 16452 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1228 16:04:42.624616 16452 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1228 16:04:42.625711 16452 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1228 16:04:44.316764 16452 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1228 16:04:44.316764 16452 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I1228 16:04:46.073973 16452 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I1228 16:04:46.073973 16452 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I1228 16:04:48.391436 16452 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I1228 16:04:48.391436 16452 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I1228 16:04:50.983051 16452 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I1228 16:04:50.983051 16452 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I1228 16:04:54.058149 16452 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I1228 16:04:54.058149 16452 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I1228 16:04:54.966184 16452 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I1228 16:04:55.091341 16452 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1228 16:04:55.449769 16452 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I1228 16:04:55.449769 16452 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
      "I1228 16:04:55.449769 16452 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
      "I1228 16:04:55.449769 16452 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I1228 16:04:55.516061 16452 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I1228 16:04:55.516061 16452 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1228 16:04:56.423986 16452 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1228 16:04:56.423986 16452 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I1228 16:04:58.358040 16452 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I1228 16:04:58.358040 16452 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I1228 16:05:00.287187 16452 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I1228 16:05:00.287187 16452 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I1228 16:05:03.041136 16452 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I1228 16:05:03.041136 16452 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I1228 16:05:06.056160 16452 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I1228 16:05:06.056160 16452 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I1228 16:05:09.775501 16452 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I1228 16:05:09.775501 16452 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I1228 16:05:11.316199 16452 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I1228 16:05:11.439085 16452 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 78.89s\n",
      "I1228 16:05:11.849552 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 78.89s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I1228 16:05:11.903804 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I1228 16:05:11.911988 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I1228 16:05:11.911988 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.01s\n",
      "I1228 16:05:11.920287 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I1228 16:05:11.924719 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I1228 16:05:11.924719 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I1228 16:05:11.928819 16452 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 89.587s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(MODELS_PATH, 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) moved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(MOBILE_NET_PATH):\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    os.makedirs(MOBILE_NET_PATH)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {MOBILE_NET_PATH}\n",
    "    !cd {MOBILE_NET_PATH} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_numpy(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    np_img = np.array(img)\n",
    "    return np_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TF_RECORD_SCRIPT_PATH):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {TF_RECORD_SCRIPT_PATH.split('\\\\')[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'thumbs_up', 'id':1}, {'name':'thumbs_down', 'id':2}, {'name':'hello', 'id':3}, {'name':'fist', 'id':4}]\n",
    "\n",
    "if not os.path.exists(LABELMAP_PATH):\n",
    "    with open(LABELMAP_PATH, 'w') as f:\n",
    "        for label in labels:\n",
    "            f.write('item { \\n')\n",
    "            f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "            f.write('\\tid:{}\\n'.format(label['id']))\n",
    "            f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: data\\records\\train.record\n",
      "Successfully created the TFRecord file: data\\records\\test.record\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join('data', 'records')):\n",
    "    os.makedirs(os.path.join('data', 'records'))\n",
    "!python {TF_RECORD_SCRIPT_PATH} -x {os.path.join(IMAGES_PATH, 'train')} -l {LABELMAP_PATH} -o {os.path.join('data', 'records', 'train.record')} \n",
    "!python {TF_RECORD_SCRIPT_PATH} -x {os.path.join(IMAGES_PATH, 'test')} -l {LABELMAP_PATH} -o {os.path.join('data', 'records', 'test.record')} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_sample(path: str):\n",
    "    classes = {\n",
    "        \"thumbs_up\": 0,\n",
    "        \"thumbs_down\": 1,\n",
    "        \"hello\": 2,\n",
    "        \"fist\": 3\n",
    "    }\n",
    "    if \".xml\" in path or \".jpg\" in path:\n",
    "        path = path.rstrip(\".xml\")\n",
    "        path = path.rstrip(\".jpg\")\n",
    "    image_path = path + \".jpg\"\n",
    "    xml_path = path + \".xml\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    data = {}\n",
    "    for elem in root.iter():\n",
    "        data[elem.tag] = elem.text\n",
    "    xmin = int(data[\"xmin\"]) / int(data[\"width\"])\n",
    "    ymin = int(data[\"ymin\"]) / int(data[\"height\"])\n",
    "    xmax = int(data[\"xmax\"]) / int(data[\"width\"])\n",
    "    ymax = int(data[\"ymax\"]) / int(data[\"height\"])\n",
    "    label = classes[data[\"name\"]]\n",
    "    np_img = image_to_numpy(image_path)\n",
    "    tf_img = tf.expand_dims(tf.convert_to_tensor(np_img, dtype=tf.float32), axis=0)\n",
    "    return {\n",
    "        \"image\": tf_img, \n",
    "        \"box\": tf.convert_to_tensor([[ymin, xmin, ymax, xmax]], dtype=tf.float32), \n",
    "        \"label\": tf.one_hot([label], depth=4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"./data/images/train/\"\n",
    "test_dataset_path = \"./data/images/test/\"\n",
    "labels = ['thumbs_up', 'thumbs_down', 'hello', 'fist']\n",
    "\n",
    "train_images = []\n",
    "train_boxes = []\n",
    "train_labels = []\n",
    "\n",
    "test_images = []\n",
    "test_boxes = []\n",
    "test_labels = []\n",
    "\n",
    "for label in labels:\n",
    "    label_path = os.path.join(train_dataset_path, label)\n",
    "    image_files = list(filter(lambda x: \".jpg\" in x, os.listdir(label_path)))\n",
    "    for file in image_files:\n",
    "        file_path = os.path.join(label_path, file)\n",
    "        data = get_dataset_sample(file_path)\n",
    "        train_images.append(data[\"image\"])\n",
    "        train_boxes.append(data[\"box\"])\n",
    "        train_labels.append(data[\"label\"])\n",
    "\n",
    "for label in labels:\n",
    "    label_path = os.path.join(test_dataset_path, label)\n",
    "    image_files = list(filter(lambda x: \".jpg\" in x, os.listdir(label_path)))\n",
    "    for file in image_files:\n",
    "        file_path = os.path.join(label_path, file)\n",
    "        data = get_dataset_sample(file_path)\n",
    "        test_images.append(data[\"image\"])\n",
    "        test_boxes.append(data[\"box\"])\n",
    "        test_labels.append(data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and restoring weights for fine-tuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights restored!\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print('Building model and restoring weights for fine-tuning...', flush=True)\n",
    "num_classes = 4\n",
    "pipeline_config = 'mobile_net\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\pipeline.config'\n",
    "checkpoint_path = 'mobile_net\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\checkpoint\\ckpt-0'\n",
    "\n",
    "# Load pipeline config and build a detection model.\n",
    "#\n",
    "# Since we are working off of a COCO architecture which predicts 90\n",
    "# class slots by default, we override the `num_classes` field here to be just\n",
    "# one (for our new rubber ducky class).\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
    "model_config = configs['model']\n",
    "model_config.ssd.num_classes = num_classes\n",
    "model_config.ssd.freeze_batchnorm = True\n",
    "detection_model = model_builder.build(\n",
    "      model_config=model_config, is_training=True)\n",
    "\n",
    "# Set up object-based checkpoint restore --- RetinaNet has two prediction\n",
    "# `heads` --- one for classification, the other for box regression.  We will\n",
    "# restore the box regression head but initialize the classification head\n",
    "# from scratch (we show the omission below by commenting out the line that\n",
    "# we would add if we wanted to restore both heads)\n",
    "fake_box_predictor = tf.compat.v2.train.Checkpoint(\n",
    "    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\n",
    "    # _prediction_heads=detection_model._box_predictor._prediction_heads,\n",
    "    #    (i.e., the classification head that we *will not* restore)\n",
    "    _box_prediction_head=detection_model._box_predictor._box_prediction_head,\n",
    "    )\n",
    "fake_model = tf.compat.v2.train.Checkpoint(\n",
    "          _feature_extractor=detection_model._feature_extractor,\n",
    "          _box_predictor=fake_box_predictor)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)\n",
    "ckpt.restore(checkpoint_path).expect_partial()\n",
    "with tf.device(\"cpu:0\"):\n",
    "    # Run model through a dummy image so that variables are created\n",
    "    image, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    _ = detection_model.postprocess(prediction_dict, shapes)\n",
    "print('Weights restored!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fine-tuning!\n",
      "batch 0 of 2000, train loss=0.6609279, val loss=0.7955948\n",
      "batch 10 of 2000, train loss=0.62604797, val loss=0.792227\n",
      "batch 20 of 2000, train loss=0.67103356, val loss=0.7863291\n",
      "batch 30 of 2000, train loss=0.651078, val loss=0.7830785\n",
      "batch 40 of 2000, train loss=0.6402905, val loss=0.77963513\n",
      "batch 50 of 2000, train loss=0.60451573, val loss=0.7767215\n",
      "batch 60 of 2000, train loss=0.64125085, val loss=0.77298677\n",
      "batch 70 of 2000, train loss=0.5723854, val loss=0.7706064\n",
      "batch 80 of 2000, train loss=0.5718476, val loss=0.76721156\n",
      "batch 90 of 2000, train loss=0.65216583, val loss=0.76392543\n",
      "batch 100 of 2000, train loss=0.6433079, val loss=0.76066977\n",
      "batch 110 of 2000, train loss=0.6361129, val loss=0.75649154\n",
      "batch 120 of 2000, train loss=0.564725, val loss=0.75603914\n",
      "batch 130 of 2000, train loss=0.6060797, val loss=0.7535943\n",
      "batch 140 of 2000, train loss=0.5862499, val loss=0.75059104\n",
      "batch 150 of 2000, train loss=0.6063098, val loss=0.74675\n",
      "batch 160 of 2000, train loss=0.5255684, val loss=0.7434918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 70\u001b[0m\n\u001b[0;32m     64\u001b[0m detection_model\u001b[38;5;241m.\u001b[39mprovide_groundtruth(\n\u001b[0;32m     65\u001b[0m     groundtruth_boxes_list\u001b[38;5;241m=\u001b[39mtest_boxes,\n\u001b[0;32m     66\u001b[0m     groundtruth_classes_list\u001b[38;5;241m=\u001b[39mtest_labels)\n\u001b[0;32m     67\u001b[0m preprocessed_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[0;32m     68\u001b[0m     [detection_model\u001b[38;5;241m.\u001b[39mpreprocess(image_tensor)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_tensor \u001b[38;5;129;01min\u001b[39;00m test_images], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m prediction_dict \u001b[38;5;241m=\u001b[39m \u001b[43mdetection_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m losses_dict \u001b[38;5;241m=\u001b[39m detection_model\u001b[38;5;241m.\u001b[39mloss(prediction_dict, shapes)\n\u001b[0;32m     72\u001b[0m val_total_loss \u001b[38;5;241m=\u001b[39m losses_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss/localization_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m losses_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss/classification_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\object_detection-0.1-py3.9.egg\\object_detection\\meta_architectures\\ssd_meta_arch.py:571\u001b[0m, in \u001b[0;36mSSDMetaArch.predict\u001b[1;34m(self, preprocessed_inputs, true_image_shapes)\u001b[0m\n\u001b[0;32m    569\u001b[0m   batchnorm_updates_collections \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mGraphKeys\u001b[38;5;241m.\u001b[39mUPDATE_OPS\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_extractor\u001b[38;5;241m.\u001b[39mis_keras_model:\n\u001b[1;32m--> 571\u001b[0m   feature_maps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    573\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m slim\u001b[38;5;241m.\u001b[39marg_scope([slim\u001b[38;5;241m.\u001b[39mbatch_norm],\n\u001b[0;32m    574\u001b[0m                       is_training\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_training \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    575\u001b[0m                                    \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freeze_batchnorm),\n\u001b[0;32m    576\u001b[0m                       updates_collections\u001b[38;5;241m=\u001b[39mbatchnorm_updates_collections):\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\object_detection-0.1-py3.9.egg\\object_detection\\meta_architectures\\ssd_meta_arch.py:252\u001b[0m, in \u001b[0;36mSSDKerasFeatureExtractor.call\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 252\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\object_detection-0.1-py3.9.egg\\object_detection\\models\\ssd_mobilenet_v2_fpn_keras_feature_extractor.py:219\u001b[0m, in \u001b[0;36mSSDMobileNetV2FpnKerasFeatureExtractor._extract_features\u001b[1;34m(self, preprocessed_inputs)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extract features from preprocessed inputs.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m    [batch, height_i, width_i, depth_i]\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    216\u001b[0m preprocessed_inputs \u001b[38;5;241m=\u001b[39m shape_utils\u001b[38;5;241m.\u001b[39mcheck_min_image_dim(\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;241m33\u001b[39m, preprocessed_inputs)\n\u001b[1;32m--> 219\u001b[0m image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassification_backbone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pad_to_multiple\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m feature_block_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fpn_min_level, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_fpn_max_level \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\engine\\functional.py:510\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    493\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\engine\\functional.py:667\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 667\u001b[0m outputs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mlayer(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    671\u001b[0m     node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)\n\u001b[0;32m    672\u001b[0m ):\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\object_detection-0.1-py3.9.egg\\object_detection\\core\\freezable_batch_norm.py:68\u001b[0m, in \u001b[0;36mFreezableBatchNorm.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=g-bool-id-comparison\u001b[39;00m\n\u001b[0;32m     67\u001b[0m   training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFreezableBatchNorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:850\u001b[0m, in \u001b[0;36mBatchNormalizationBase.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused:\n\u001b[1;32m--> 850\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fused_batch_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;66;03m# Currently never reaches here since fused_batch_norm does not\u001b[39;00m\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;66;03m# support virtual batching\u001b[39;00m\n\u001b[0;32m    854\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m undo_virtual_batching(outputs)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:660\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fused_batch_norm_inference\u001b[39m():\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfused_batch_norm(\n\u001b[0;32m    650\u001b[0m         inputs,\n\u001b[0;32m    651\u001b[0m         gamma,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    657\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_format,\n\u001b[0;32m    658\u001b[0m     )\n\u001b[1;32m--> 660\u001b[0m output, mean, variance \u001b[38;5;241m=\u001b[39m \u001b[43mcontrol_flow_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fused_batch_norm_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fused_batch_norm_inference\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    663\u001b[0m variance \u001b[38;5;241m=\u001b[39m _maybe_add_or_remove_bessels_correction(\n\u001b[0;32m    664\u001b[0m     variance, remove\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    665\u001b[0m )\n\u001b[0;32m    667\u001b[0m training_value \u001b[38;5;241m=\u001b[39m control_flow_util\u001b[38;5;241m.\u001b[39mconstant_value(training)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\utils\\control_flow_util.py:108\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pred, tf\u001b[38;5;241m.\u001b[39mVariable):\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(pred, true_fn\u001b[38;5;241m=\u001b[39mtrue_fn, false_fn\u001b[38;5;241m=\u001b[39mfalse_fn, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:54\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m true_fn()\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfalse_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m control_flow_ops\u001b[38;5;241m.\u001b[39mcond(pred, true_fn\u001b[38;5;241m=\u001b[39mtrue_fn, false_fn\u001b[38;5;241m=\u001b[39mfalse_fn,\n\u001b[0;32m     57\u001b[0m                                name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:649\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm.<locals>._fused_batch_norm_inference\u001b[1;34m()\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fused_batch_norm_inference\u001b[39m():\n\u001b[1;32m--> 649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfused_batch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoving_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoving_variance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32md:\\Edu\\Python_Projects\\Object_Detection\\.conda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:1702\u001b[0m, in \u001b[0;36mfused_batch_norm\u001b[1;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[0;32m   1689\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m epsilon \u001b[38;5;28;01mif\u001b[39;00m epsilon \u001b[38;5;241m>\u001b[39m min_epsilon \u001b[38;5;28;01melse\u001b[39;00m min_epsilon\n\u001b[0;32m   1691\u001b[0m y, running_mean, running_var, _, _, _ \u001b[38;5;241m=\u001b[39m gen_nn_ops\u001b[38;5;241m.\u001b[39mfused_batch_norm_v3(\n\u001b[0;32m   1692\u001b[0m     x,\n\u001b[0;32m   1693\u001b[0m     scale,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1700\u001b[0m     is_training\u001b[38;5;241m=\u001b[39mis_training,\n\u001b[0;32m   1701\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m-> 1702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y, running_mean, running_var\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "# These parameters can be tuned; since our training set has 5 images\n",
    "# it doesn't make sense to have a much larger batch size, though we could\n",
    "# fit more examples in memory if we wanted to.\n",
    "batch_size = 16\n",
    "learning_rate = 0.05\n",
    "num_batches = 2000\n",
    "\n",
    "# Select variables in top layers to fine-tune.\n",
    "trainable_variables = detection_model.trainable_variables\n",
    "to_fine_tune = []\n",
    "prefixes_to_train = [\n",
    "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\n",
    "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\n",
    "for var in trainable_variables:\n",
    "  if any([var.name.startswith(prefix) for prefix in prefixes_to_train]):\n",
    "    to_fine_tune.append(var)\n",
    "\n",
    "def get_model_train_step_function(model, optimizer, vars_to_fine_tune):\n",
    "  \"\"\"Get a tf.function for training step.\"\"\"\n",
    "\n",
    "  @tf.function\n",
    "  def train_step_fn(image_tensors,\n",
    "                    groundtruth_boxes_list,\n",
    "                    groundtruth_classes_list):\n",
    "    shapes = tf.constant(batch_size * [[640, 640, 3]], dtype=tf.int32)\n",
    "    model.provide_groundtruth(\n",
    "        groundtruth_boxes_list=groundtruth_boxes_list,\n",
    "        groundtruth_classes_list=groundtruth_classes_list)\n",
    "    with tf.GradientTape() as tape:\n",
    "      preprocessed_images = tf.concat(\n",
    "          [detection_model.preprocess(image_tensor)[0]\n",
    "           for image_tensor in image_tensors], axis=0)\n",
    "      prediction_dict = model.predict(preprocessed_images, shapes)\n",
    "      losses_dict = model.loss(prediction_dict, shapes)\n",
    "      total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\n",
    "      gradients = tape.gradient(total_loss, vars_to_fine_tune)\n",
    "      optimizer.apply_gradients(zip(gradients, vars_to_fine_tune))\n",
    "    return total_loss\n",
    "\n",
    "  return train_step_fn\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "train_step_fn = get_model_train_step_function(\n",
    "    detection_model, optimizer, to_fine_tune)\n",
    "\n",
    "print('Start fine-tuning!', flush=True)\n",
    "for idx in range(num_batches):\n",
    "  all_keys = list(range(len(train_images)))\n",
    "  random.shuffle(all_keys)\n",
    "  example_keys = all_keys[:batch_size]\n",
    "\n",
    "  gt_boxes_list = [train_boxes[key] for key in example_keys]\n",
    "  gt_classes_list = [train_labels[key] for key in example_keys]\n",
    "  image_tensors = [train_images[key] for key in example_keys]\n",
    "\n",
    "  with tf.device(\"cpu:0\"):\n",
    "    total_loss = train_step_fn(image_tensors, gt_boxes_list, gt_classes_list)\n",
    "\n",
    "  if idx % 10 == 0:\n",
    "    with tf.device(\"cpu:0\"):\n",
    "      shapes = tf.constant(batch_size * [[640, 640, 3]], dtype=tf.int32)\n",
    "      detection_model.provide_groundtruth(\n",
    "          groundtruth_boxes_list=test_boxes,\n",
    "          groundtruth_classes_list=test_labels)\n",
    "      preprocessed_images = tf.concat(\n",
    "          [detection_model.preprocess(image_tensor)[0]\n",
    "          for image_tensor in test_images], axis=0)\n",
    "      prediction_dict = detection_model.predict(preprocessed_images, shapes)\n",
    "      losses_dict = detection_model.loss(prediction_dict, shapes)\n",
    "      val_total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\n",
    "    print('batch ' + str(idx) + ' of ' + str(num_batches)\n",
    "    + ', train loss=' +  str(total_loss.numpy()) \n",
    "    + \", val loss=\" + str(val_total_loss.numpy()), flush=True)\n",
    "\n",
    "print('Done fine-tuning!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_trained = tf.train.Checkpoint(model=detection_model)\n",
    "if not os.path.exists(TRAINED_MODEL_PATH):\n",
    "    ckpt_trained.save(TRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect(input_tensor, model):\n",
    "  preprocessed_image, shapes = model.preprocess(input_tensor)\n",
    "  prediction_dict = model.predict(preprocessed_image, shapes)\n",
    "  return model.postprocess(prediction_dict, shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = {\n",
    "    1: {\"id\": 1, \"name\": \"thumbs_up\"},\n",
    "    2: {\"id\": 2, \"name\": \"thumbs_down\"},\n",
    "    3: {\"id\": 3, \"name\": \"hello\"},\n",
    "    4: {\"id\": 4, \"name\": \"fist\"}\n",
    "}\n",
    "label_id_offset = 1\n",
    "\n",
    "\n",
    "def plot_img_with_detection(tf_image, model):\n",
    "    np_image = np.array(tf_image[0], dtype=np.uint8)\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        detections = detect(tf_image, model)\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        np_image,\n",
    "        detections[\"detection_boxes\"][0].numpy(),\n",
    "        np.array(detections[\"detection_classes\"][0], dtype=np.int32)+label_id_offset,\n",
    "        detections[\"detection_scores\"][0].numpy(),\n",
    "        category_index,\n",
    "        min_score_thresh=0.3,\n",
    "        max_boxes_to_draw=1,\n",
    "        use_normalized_coordinates=True\n",
    "    )\n",
    "    plt.imshow(np_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1cd1bf120a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del detection_model\n",
    "model = model_builder.build(model_config, False)\n",
    "ckpt_trained = tf.train.Checkpoint(model=model)\n",
    "ckpt_trained.restore(TRAINED_MODEL_PATH + \"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"cpu:0\"):\n",
    "    image, shape = model.preprocess(tf.random.uniform((1, 640, 640, 3)))\n",
    "    pred = model.predict(image, shape)\n",
    "    output = model.postprocess(pred, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing pipeline config file to ./mobile_net/trained_model\\pipeline.config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing pipeline config file to ./mobile_net/trained_model\\pipeline.config\n"
     ]
    }
   ],
   "source": [
    "config_util.save_pipeline_config(model_config, \"./mobile_net/trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while vid.isOpened(): \n",
    "    ret, frame = vid.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        detections = detect(input_tensor, model)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections[\"detection_boxes\"][0].numpy(),\n",
    "                np.array(detections[\"detection_classes\"][0], dtype=np.int32)+label_id_offset,\n",
    "                detections[\"detection_scores\"][0].numpy(),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=2,\n",
    "                min_score_thresh=.5,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        vid.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
